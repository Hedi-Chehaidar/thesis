% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{chapter:conclusion}

\sparagraph{Reduced Greediness.} The contributions discussed in this thesis helped with reducing the greedy aspect of the symbol table construction and compression in FSST. The DP approach that replaced the greedy function improved the quality of chosen symbols, optimizing each generation locally, which also affected the resulting symbol table. The DP approach proved to be more effective during final compression after building the symbol table. Replacing the greedy approach allowed smaller symbols to be chosen during \texttt{compressCount} which led to the second contribution (third frequency counter) to favor longer concatenations. Then symbol pruning was introduced to correct the gains of the candidate symbols on the fly during the table filling process of each generation. The gain heuristic is static and does not account for conflicts between overlapping symbols, which contributed to the overall greedy aspect of the original FSST algorithm.

\sparagraph{Better Compression Factors.} BtrFSST, the algorithm including all of the contributions, improved the average compression factor of the original FSST algorithm by 9.6\%. This was the conclusion of benchmarking both methods over a wide selection of heterogeneous real-world string columns, including different types of information like URLs, dates, names, codes, and long texts. The best compression factor improvement recorded in the datasets was 47.7\%, while the average improvement was by 7.3\%, which shows the potential of the contributions in compressing data exhibiting common substrings, especially digit-containing data. The extensive benchmarking of the different combinations of improvements showed a possibility to obtain a better compression factor when using only subsets of the contributions. However, this compression factor improvement is still not significant, as it requires multiple compressions for the same column only for an additional 1.4\% average compression factor gain (over FSST). 

BtrFSST also proved to be useful for other compression methods that use FSST like Dict FSST, which benefited with an improvement of the average compression factor by 1.1\% with duplicate-heavy data. This improvement depends mainly on the amount of duplicates in the data: the fewer duplicates there are, the more the compression factor improves. 

\sparagraph{Runtime Overhead.} When benchmarking the average compression speed of both FSST and BtrFSST on the selected datasets, a slowdown of 78.3\% was documented. This runtime overhead comes primarily from adding DP to the full column compression after the symbol table construction. The improvements on the symbol table construction had a 30.8\% slowdown, making encoding the real bottleneck of BtrFSST. Further research on the possibilities of reducing branching or using SIMD instructions in the DP function can reduce this overhead significantly.

BtrFSST still uses the same decompression method of FSST, whose speed is more decisive when it comes to using compressed data in database systems for query throughputs, as the data is only compressed once.

