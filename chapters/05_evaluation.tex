% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Evaluation}\label{chapter:evaluation}

In this section we will discuss the effects of the three introduced contributions on the original FSST algorithm in terms of compression factor and encoding speed across different datasets. The contributions will be also tested against DICT FSST \cite{dict_fsst}, which combines dictionary encoding with applying FSST to the dictionary values.

\section{Benchmarking Data}

\subsection{Dbtext}

This is the dataset used for benchmarking in the original FSST paper~\cite{fsst}. It includes real-world text data from different sources. The data consists of 23 string columns ranging from 130~KB (city) to around 6~MB (urls) in size. They can be grouped in five categories based on their data nature:
\begin{itemize}
  \item machine-readable identifiers: hex, yago, email, wiki, uuid, urls2, and urls.
  \item human-readable names: firstname, lastname, city, credentials, street, and movies.
  \item text: faust, hamlet, chinese, japanese, and wikipedia.
  \item domain-specific codes: genome and location
  \item TPC-H data: c\_name, l\_comment, and ps\_comment
\end{itemize}

\subsection{NextiaJD}

NextiaJD~\cite{nextiajd} has a collection of diverse string columns, dedicated to learning-based research. The selected tables from NextiaJD are:
\begin{itemize}
  \item github-issues: it has the largest column of the considered benchmarking data in this thesis (body) with 32~MB size.
  \item glassdoor: the table with the most string columns, the majority being URLs and path links. 
  \item Homo\_sapiens.GRCh38.92: duplicate heavy data and identifiers.
  \item Parking\_Violations\_Issued\_Fiscal\_Year\_2017: containing street names and columns with short rows.
  \item Reddit\_Comments\_7M\_2019: the majority of columns are usernames, but also contains one text column (body) and one column with links (permalink).
  \item reviews\_detailed: contains large text data (comments).
\end{itemize}

\subsection{PublicBIbenchmark}

PublicBIbenchmark is a dataset produced by CWI (Centrum Wiskunde \& Informatica) with data representing real-world business intelligence workloads \cite{publicbibenchmark}. The data selected combines geographical locations, URLs with prefix-heavy patterns, and user-generated data in different languages containing special characters (hashtags) to test the effect of the improvements on heterogeneous data. The tables chosen from this dataset are ``HashTags/Hashtags1'' and ``IGlocations2/IGlocations2\_2''. Each of these tables has a significant amount of string columns. Combined, they contain all mentioned types of data. 


\subsection{CyclicJoinBench}

CyclicJoinBench is a dataset used to evaluate join algorithms on cyclic query graphs~\cite{cyclicjoinbench}. The datasets contains three identical tables regarding content types, therefore only one table was used for benchmarking (SNB1-parquet). Most of the string columns of this dataset have short rows featuring names, titles, and locations.


\subsection{ClickBench}

ClickBench is a dataset developed by ClickHouse~\cite{clickbench}, used to benchmark the performance of over 50 databases on simple analytical workloads. This makes the dataset suitable for the evaluation of compression methods. ClickBench has only three string-type columns that were all used for benchmarking: Title, Referer, and URL.


\section{Benchmarking Method}
\label{benchmarking_method}

A filtering process was applied on the selected tables from the datasets mentioned above, in order to get string columns suitable for benchmarking the effects of the improvements.

First, each table is reduced to its first 100~K rows. Then, to eliminate columns with numeric values, the only allowed column type was VARCHAR. Furthermore, an additional check was applied to filter out columns having date or datetime data.

To simulate real-world workload conditions, only columns having at least 1~K rows are kept for benchmarking.

Another filtering condition was setting an upper-bound of 35~MB for the columns. Larger columns have very long strings in each row and are usually compressed best using block-based compressors like zstd.
\newline
\begin{comment}
\newline
\sparagraph{DICT FSST Fairness.} To ensure a fair comparison with DICT FSST, the resulting columns should not be dominated by duplicates. Otherwise, the DICT FSST compression will be mostly influenced by the dictionary encoding phase, which consists in keeping a dictionary to map each row to its value in a duplicate-free version of the column. The second phase of the DICT FSST is the more relevant part for the comparison, as it uses FSST to compress the unique columns, i.e, the contributions of the thesis are only applicable in this phase. As a result, only columns whose FSST compression sizes are smaller than their dictionary encoding sizes are retained. 
\end{comment}

\sparagraph{Dictionary Encoding.} Duplicate-heavy columns in the datasets can be better compressed with dictionary encoding~\cite{dict1, dict2, dict3, dict4}, which consists in keeping a dictionary with the unique values and a second field that contains, for each row in the original column, the index of the corresponding value in the deduplicated column. DICT FSST uses dictionary encoding in its first phase, then applies FSST to compress the dictionary, which leads to higher compression factors.

The condition used for filtering is: $\text{FSST compressed size} \le \text{Dictionary encoding size}$. The size of the dictionary is calculated as the sum of the lengths of unique strings and the total size of the integers used for mapping (bitpacked).

Columns that are filtered with this condition will be included again when benchmarking the effect of introducing the contributions to the second phase of DICT FSST. 

\section{Results}

\subsection{Ablation Study}

We are going to discuss the effect of the contributions of this thesis (DP, third counter, and pruning) on the FSST algorithm regarding compression factor (CF) and encoding speed. The resulting codebase~\cite{btrfsst_repo} is an extension of the original FSST code~\cite{fsst_repo}, allowing the inclusion of the improvements with command line options as follows:

\begin{itemize}
  \item no options: Exactly FSST will be run.
  \item \-\-dp-train: The DP function will be used for building the symbol table instead of the greedy \texttt{findLongestSymbol}.
  \item \-\-dp-encode: The DP function will be used for compressing the whole corpus after constructing the symbol table.
  \item \-\-triples: \texttt{compressCount} will use three counters instead of two.
  \item \-\-prune: Pruning will be used in the filling of the new symbol table in each generation in \texttt{makeTable}.
\end{itemize}

Running the base code with any configuration different than FSST (i.e, with at least one of the options above) will discard some of the heuristics used by the original FSST code. These heuristics include a $\times 8$ boost to the gain of one-byte symbols, using fractions of the sample incrementally across generations instead of training on the whole sample for the 5 generations, and setting an entry threshold for the count of the symbols before pushing them to the heap of candidates.

The program running with all the above mentioned options will be called ``BtrFSST'', where all improvements are combined with FSST as a base.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/cf\_combined}
  \caption{Improvement of the contributions on the compression factor against FSST.}
  \label{cf_combined}
\end{figure}

\sparagraph{CF Benchmarking.} Figure~\ref{cf_combined} shows the compression factor improvement over all the selected columns of the datasets with different configurations. All improvements are measured against FSST (red line). The left side adds the improvements, affecting only the symbol table construction (the full column compression is still greedy). The right side always includes DP in full column encoding and then adds the contributions gradually in the same way.

The average per-file compression factor improvement by BtrFSST was at 7.3\%. Without including DP in full column encoding, the contributions have an average improvement of 2.5\% by solely improving the symbol table construction, while the improvement was by 3.4\% when DP was used in full corpus compression. This shows that not using the greedy \texttt{findLongestSymbol} at all has a stronger impact on the overall compression factor. The implementation backs this claim, as when DP is used on both table construction and column compression, there is no need to store symbols in a hash table. Therefore in that case, all symbols selected will be used in the symbol table, without the possibility for collisions, which was certain for symbols sharing the first three bytes, the key for the hash function in FSST.  

DP compression of the columns after symbol table construction has the highest effect on the average compression factor improvement with 3.9\% over FSST with greedy encoding. Then comes DP in table construction (2.6\% with DP in full column encoding and 1.7\% without), which shows that the greedy approach was the main reason behind the sub-optimal compression factors of the original FSST. Although adding a third counter and using symbol pruning during symbol table filling did not have significant effects on the overall compression factor improvement, they can still be helpful for some workloads (discussed later). 
\newline
\sparagraph{Compression Speed Benchmarking.}  The machine used for this benchmarking is a laptop equipped with an AMD Ryzen 9 CPU with 8 cores and 16 threads, operating at a base frequency of 3.3~GHz. The system uses 16~GB of RAM and an integrated AMD Radeon Graphics, with storage being provided by an NVMe SSD. All benchmarks were executed with the device connected to external power and configured in high-performance mode. No SIMD code was executed, meaning that the compression method used for original FSST was the scalar one, and not with AVX-512 which would be $\times 2.5$ faster~\cite{fsst}. 

\clearpage

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/time\_combined}
  \caption{Effect of the contributions on the compression speed against FSST.}
  \label{time_combined}
\end{figure}

Figure~\ref{time_combined} shows the encoding speed slowdown with the different configurations over all columns. The baseline is here again FSST (red line).

The benchmarks show that BtrFSST is on average 78.3\% slower than FSST. The added compression time overhead comes primarily from DP in full column encoding, which alone increased compression speed by 63\% on average. The contributions affecting the symbol table construction made the algorithm 30.8\% slower than FSST, but added only a 15.3\% slowdown comparing to FSST with DP in full column encoding. This proves that the bottleneck is the full column compression with DP, especially with columns that are significantly larger than the sample size (16~KB). 

\sparagraph{Worst Performance.} BtrFSST performed worse than FSST on 10 files from a total of 92 files of the whole datasets combined. The column with the worst performance against FSST (7.6\% less compression factor) is Reddit\_Comments\_7M\_2019::id from the NextiaJD dataset, while all other columns are not more than 3.1\% worse than FSST. For the id column the compression factor was the highest using only the DP approach (in table construction and column encoding) with a compression factor of 1.68 against 1.64 for FSST.  

We can conclude that some of the contributions of this thesis may be degrading the compression factor for some columns. This issue will be addressed in future work to guarantee that no contribution has a negative effect on the compression factor, regardless of the sampled data and the type of data in the column.   

\sparagraph{Best Performance.} BtrFSST performed significantly better than FSST on the majority of the columns, with 6 columns having more than 20\% compression factor improvement. The column with the best performance, reaching an improvement of 47.7\% in the compression factor, is Parking\_Violations\_Issued\_Fiscal\_Year\_2017::Registration\_State from the NextiaJD dataset. This column features state abbreviations, with each row having a string of length two. Experiments showed that BtrFSST performs best on columns with shorter strings and strings including numeric values.
\begin{comment}
Figure~\ref{cf_worst} shows the significant columns where BtrFSST performed worse than FSST. The first column is the smallest one in the whole benchmarking data with just 71 rows and a total size of 1~KB. Noticing that also FSST with just 4 encoding had a worse compression factor on this file (Figure~\ref{cf_combined}) explains that this difference is purely due to the heuristics used in the original FSST code, which were discarded for every other configuration. We can conclude that those heuristics only work for very small columns (CF is better on average without them even for FSST).

The second and third columns come from the same table ``NextiaJD/Homo\_sapiens.GRCh38.92'' and they exhibit redundancies over small blocks of lengths from 5 to 15 rows each. ``protein\_id'' is a similar column to the third one and is also from the same table. However, it showed a contrary effect, i.e., BtrFSST had better CF (3.28 to 3.17). A close look into the changments of CF across configurations shows that ``ccds\_id'' was negatively affected when both adding DP on training and pruning (with DP on encoding), while ``transcript'' showed a drop in the CF after adding the third counter and pruning. A possible explanation is the problem of the sampling mechanism that was not helpful for some of the contributions, leading to choosing a set of symbols that does not generalize well over the whole corpus and making a greedy approach superior.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/CF\_best}
  \caption{Best performance of BtrFSST against FSST.}
  \label{cf_best}
\end{figure}


\sparagraph{Best Performance.} BtrFSST performed significantly better than FSST on the majority of the columns, reaching an improvement of 47.3\% on column ``Parking\_Violations\_Issued\_Fiscal\_Year\_2017::Issue\_Date'' from the NextiaJD dataset. Figure~\ref{cf_best} shows the best three files for the contributions. The common factor between those columns is the presence of many common substrings across the rows, either through redundancies of the whole strings over a long streak of rows (last two columns) or through sharing suffixes like in dates.
\end{comment}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/best\_config}
  \caption{Compression factor improvement against FSST when choosing the best configuration.}
  \label{best_config}
\end{figure}
\clearpage

\sparagraph{Best Configuration.} Figure~\ref{best_config} shows the compression factor improvement against FSST when choosing the best configuration for each file independently (Best) from the 7 configurations shown in Figure~\ref{cf_combined} and including FSST itself as an $8^{th}$ configuration. The average per-file compression factor improvement from FSST is at 8.8\%, which is not significantly higher than always compressing with BtrFSST, that shows a 7.3\% average per-file compression factor improvement. Below are the counts for each configuration, of how many files it had the best compression factor:

\begin{itemize}

  \item FSST:                                   2  (2.1\%)
  \item FSST + dp-train:                        5  (5.4\%) 
  \item FSST + dp-train + triples:              5  (5.4\%) 
  \item FSST + dp-train + triples + prune:      2  (2.1\%)
  \item FSST + dp-encode:                       6  (6.5\%)
  \item FSST + dp-encode + dp-train:            18 (19.5\%)
  \item FSST + dp-encode + dp-train + triples:  24 (26.0\%)
  \item BtrFSST:                                30 (32.6\%)

\end{itemize}

The distribution proves that BtrFSST is the best configuration, although a noticeable number of files compress better with a subset of the improvement and their compression factors drop when adding other options. However, this drop is not significant and a rule of thumb can be using BtrFSST by default unless small improvements are worth the additional computational overhead of compressing the same file multiple times to find the best configuration. 

\subsection{Block-Based Compressors}

The two Figures~\ref{block_cf}~and~\ref{block_time} show that for the selected datasets, general purpose compressors perform better than both FSST and BtrFSST in terms of compression factor and compression speed. This is due to the high shared substrings between the rows of the datasets, especially prefixes in URLs and identifiers.

LZ4 has a $\times 1.9$ better compression factor and is $\times 6.8$ faster than BtrFSST, while Zstd has a $\times 3.7$ higher compression factor and is $\times 4$ faster than BtrFSST.
LZ4 is therefore optimized for speed while Zstd gives better compression factors, which supports what was mentioned in Section~\ref{block-based_compressors}.

Although both LZ4 and Zstd are faster and compress better than both BtrFSST and FSST, these block-based compressors stay inefficient for decompressing individual strings, as the whole surrounding block must be first decompressed before accessing a single string.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/block_cf}
  \caption{Comparison of compression factors with LZ4 and Zstd.}
  \label{block_cf}
\end{figure}


\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/block_time}
  \caption{Comparison of compression speed with LZ4 and Zstd.}
  \label{block_time}
\end{figure}
\clearpage

\subsection{DICT FSST}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{figures/CF\_dict}
  \caption{Effect of the contributions on the compression factor with DICT FSST, including duplicate-heavy columns.}
  \label{cf_dict}
\end{figure}

Figure~\ref{cf_dict} shows the effect of the contributions on the DICT FSST compression. All columns filtered out by the condition on the dictionary encoding size mentioned in Section~\ref{benchmarking_method} are included in this benchmark.

DICT FSST benefited from the duplicate-heavy columns, as it shows a higher average compression factor compared to FSST by $\times 3.6$.

BtrFSST performs better on such columns and shows a higher improvement of the average compression factor from FSST than on the data without duplicate-heavy columns (15.4\%). However, the effects of the contributions are no longer as significant with dictionary encoding (DICT BtrFSST). The small improvement (1.1\%) over DICT FSST is due to the smaller dictionaries in duplicate-heavy data, making the compression mainly influenced by the dictionary encoding phase. 


