% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Evaluation}\label{chapter:evaluation}

In this section we will discuss the improvement of the three introduced contributions on the original FSST algorithm in terms of compression factor across different datasets. The contributions will be also tested against other compression techniques that use FSST, like DICT FSST \cite{dict_fsst} and FSST+ \cite{fsst_plus_repo}. Then the additional runtime overhead of the improvements will be discussed at the end. 

\section{Benchmarking Data}

\subsection{Dbtext}

This is the dataset used for benchmarking in the original FSST paper~\cite{fsst}. It includes real-world text data from different sources. The data consists of 23 string columns ranging from 130~KB (city) to around 6~MB (urls) in size. They can be grouped in five categories based on their data nature:
\begin{itemize}
  \item machine-readable identifiers: hex, yago, email, wiki, uuid, urls2, and urls.
  \item human-readable names: firstname, lastname, city, credentials, street, and movies.
  \item text: faust, hamlet, chinese, japanese, and wikipedia.
  \item domain-specific codes: genome and location
  \item TPC-H data: c\_name, l\_comment and ps\_comment
\end{itemize}

\subsection{NextiaJD}

NextiaJD~\cite{nextiajd} has a collection of diverse string columns, dedicated to learning-based research. The selected tables from NextiaJD are:
\begin{itemize}
  \item github-issues: it has the largest column of the whole benchmarking data (body) with 32~MB size.
  \item glassdoor: the table with the most string columns, the majority being urls and path links. 
  \item Homo\_sapiens.GRCh38.92: mostly duplicate heavy data (identifiers).
  \item Parking\_Violations\_Issued\_Fiscal\_Year\_2017: containing street names and dates.
  \item Reddit\_Comments\_7M\_2019: the majority of columns are usernames, but also contains one text column (body) and one column with links (permalink)
  \item reviews\_detailed: it combines date data with large text data.
\end{itemize}

\subsection{PublicBIbenchmark}

PublicBIbenchmark is a dataset produced by CWI (Centrum Wiskunde \& Informatica) with data representing real-world business intelligence workloads \cite{publicbibenchmark}. The data selected combine geographical locations, urls with prefix-heavy patterns, and user-generated data in different languages and special characters (hashtags) to test the affect of the improvements with heterogenous data. The tables chosen from this dataset are ``HashTags/Hashtags1'', ``IGlocations2/IGlocations2\_2'', and ``YaleLanguages/YaleLanguages\_1''. 


\subsection{CyclicJoinBench}

CyclicJoinBench is a dataset used to evaluate join algorithms on cyclic query graphs~\cite{cyclicjoinbench}. The datasets contains three identical string containing tables regarding content, therefore only one table was used for benchmarking (SNB1-parquet). Most of the string columns of this dataset has short rows featuring names, titles, and locations.


\subsection{ClickBench}

ClickBench is a dataset developed by ClickHouse~\cite{clickbench}, used to benchmark the performance of over 50 databases on simple analytical workloads. This makes the dataset suitale for the evaluation of compression methods. ClickBench has only three string type columns that were all used for benchmarking: Title, Referer, and URL.


\section{Benchmarking Method}

A filtering process was applied on the selected tables from the datasets mentioned above in order to get string columns suitable for benchmarking the affects of the improvements. The filtering conditions are the same used for benchmarking FSST+, mentioned in the corresponding thesis~\cite{fsst_plus}.

First, each relation is reduced to its first 100~K rows. Then, to eliminate columns with numeric values, the only allowed column type was VARCHAR. Furthermore, only columns having an average row length $\ge 8$ were retained. An exception is the dbtext dataset that was taken fully as is, although it had a column with an average length of 7 (firstname). 
\newline
\sparagraph{DICT FSST fairness.}To ensure a fair comparison with DICT FSST, the resulting columns should not be dominated by duplicates. Otherwise, the DICT FSST compression will be mostly influenced by the dictionary encoding, which consists of keeping a dictionary to map each row to its value in a duplicate-free version of the column. The second part of the DICT FSST is the more relevant part for the comparison, as it uses FSST to compress the unique columns, i.e, the contributions of the thesis are only applicable in this part. As a result, only columns whose FSST compression size is not more than twice the size of dictionary encoding are retained. 

The condition used is then $\text{FSST compressed size} \le 2 \times \text{Dictionary encoding size}$. The size of the dictionary is calculated as the sum of the lengths of unique strings and the total size of tha integers used for mapping, according to the SQL query of Lst.~\ref{dict}.

\begin{lstlisting}[language=SQL, caption={SQL query to get dictionary encoding size.}, label={dict}]
SELECT
  CAST(
    COALESCE(length(string_agg(DISTINCT col, '')), 0) -- length of unique strings
    +
    (COUNT(col) * CASE -- total number of strings * bytes used to map each string
        WHEN COUNT(DISTINCT col) = 0 THEN 0
        ELSE ceil(log2(COUNT(DISTINCT col)) / 8) -- bits / 8 to count bytes
      END
    )
  AS BIGINT) AS total_compressed_size
  FROM rel
\end{lstlisting}


\noindent
An additional cndition was applied, that was not used for benchmarking FSST+, setting an upper-bound of 35~MB for the resulting text file of each column, in order to eliminate huge files that skewed the average runtime measure. 

\section{Results}

\subsection{Ablation Study}


