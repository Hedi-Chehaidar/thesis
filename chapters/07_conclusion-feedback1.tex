% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{chapter:conclusion}

\sparagraph{Reduced Greediness.} The contributions discussed in this thesis helped with reducing the greedy aspect of the symbol table construction and compression in FSST. The DP approach that replaced the greedy function improved the quality of chosen symbols, optimizing each generation locally, which also affected the resulting symbol table. The DP approach proved to be more effective during final compression after building the symbol table. Replacing the greedy approach allowed smaller symbols to be chosen during \texttt{compressCount} which led to the second contribution (third frequency counter) to favor longer concatenations. Then symbol pruning was introduced to correct the gains of the candidate symbols on the fly during the table filling process of each generation. The gain heuristic is static and does not account for conflicts between overlapping symbols, which contributed to the overall greedy aspect of the original FSST algorithm.

% Mihail: In text, please use "Compression Factor".
\sparagraph{Better CF.} BtrFSST, the algorithm including all of the contributions, improved the average compression factor of the original FSST algorithm by 9.6\%. This was the conclusion of benchmarking both methods over a wide selection of heterogeneous real-world string columns, including different types of information like URLs, dates, names, codes and long texts. The best CF improvement recorded in the datasets was 47.7\%, which shows the potential of the contributions in compressing data exhibiting common substrings, especially digit-containing data. The extensive benchmarking of the different combinations of improvements showed a possibility to obtain a better CF when using only subsets of the contributions. However, this CF improvement is still not significant, as it requires multiple compressions for the same column only for an additional 1.5\% average CF gain (over FSST). 

% Mihail: Also update this part once done with the unfiltered dataset for the Dict FSST benchmark.
BtrFSST also proved to be useful for other compression methods that use FSST like Dict FSST, which benefited with an average CF improvement of 3.4\%. This improvement depends mainly on the amount of duplicates in the data: the fewer duplicates there are, the more the CF improves. 

% Mihail: On the other hand, [...] why is bad that we're using the same decompression?
\sparagraph{Runtime Overhead.} When benchmarking the average runtime of both FSST and BtrFSST on the selected datasets, a slowdown of 88.1\% was documented. This runtime overhead comes primarily from adding DP on compression after the symbol table construction. The improvements on the symbol table construction had a 30.5\% slowdown, making encoding the real bottleneck of BtrFSST. Further research on the possibilities of reducing branching or using SIMD instructions in the DP function can reduce this overhead significantly. On the other hand, BtrFSST still uses the same decompression of FSST, whose speed is more decisive when it comes to using compressed data in database systems for query throughputs, as the data is only compressed once.

