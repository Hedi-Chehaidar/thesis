% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Approach}\label{chapter:approach}

\lstset{%
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  xleftmargin=2em
}

\section{Dynamic Programming}
\label{dp}

\subsection{Idea and Formula}

The first contribution of the thesis to the FSST algorithm of Lst.~\ref{algorithm3} is replacing the \texttt{st.findLongestSymbol} method with a DP function that gives "one" best symbol given the position in the text to encode (or training text in compressCount) with a single table lookup in $O(1)$ runtime. This table called \texttt{opt} is constructed simultaneously with the DP table.
\newline

\noindent
To understand the utility of the used DP function in the code, let us first define the more intuitive DP function for $0 \le i \le n$ (where $n$ is the text length) as: 
\[
  dp[i] = \text{smallest compressed size of the first $i$ bytes of the given text.}
\]
The result for the whole text is therefore stored in $dp[n]$. The base case is $dp[0] = 0$ as the compression of an empty string is always an empty string.
The recurrence is defined for each other value as: 
\begin{equation}
\label{formula1}
dp[i] = \min(2 + dp[i-1], 1 + \min\limits_{\substack{0 \le j < i \\ s[j:i] \in symbols}} dp[j])
\end{equation}
where \texttt{s[j:i]} denotes the substring of the text from position $j$ to $i-1$ (0-indexed). The formula simply chooses between either escaping the current byte or selecting one symbol that minimizes the DP value.
In the first case, an overhead of two bytes must be added caused by the escape byte followed by the raw byte from the string during encoding. In the second case, one additional byte is emitted for the code of the chosen symbol. All candidate symbols are the ones that match a suffix of the first $i$ bytes, thus the constraints under the second $min$.

However, this formulation is not suitable for constructing \texttt{opt} on the fly: it iterates over symbols that end at position $i$, while \texttt{opt[i]} must store the best symbol that starts at position $i$. 
\newline

\noindent
Therefore, the following DP function is used instead, defined for $0 \le i \le n$ as: 
\[
  dp[i] = \text{smallest compressed size of the last $n-i$ bytes of the given text.}
\]
This is equivalent to say that $dp[i]$ is the smallest compressed size of the suffix of the given text starting at position $i$ (0-indexed). The result for the whole text is therefore stored in $dp[0]$. The base case is $dp[n] = 0$ as the suffix from position $n$ is an empty string.
The recurrence is defined for each other position as:
\begin{equation}
\label{formula2}
dp[i] = \min(2 + dp[i+1], 1 + \min\limits_{\substack{i < j \le n \\ s[i:j] \in symbols}} dp[j]).
\end{equation}
The two options to choose from are the same as in the previous formula, but candidate symbols for the second option must now begin at position $i$ as we are now calculating the results for suffixes instead of prefixes of the given text.
\newline

\noindent
This DP problem is a segmentation problem, where each segment is either a symbol, the escape code or a raw byte of the string that must follow the escape code. All segments have the same cost and we want to minimize the number of segments used to compress a given text. The first formula builds a bottom-up solution, while the second formula builds a top-down solution. Both formulations yield the same optimal cost for the whole text, as they solve the same problem. 

\subsection{Implementation}

The code in Lst.~\ref{dp_python} represents the python implementation of the DP function \texttt{st.buildDP} that fills both the DP and the \texttt{opt} tables in a single pass.

\begin{lstlisting}[language=Python, caption={DP construction for \texttt{dp} and \texttt{opt} implementing Eq.~\eqref{formula2}.}, label={dp_python}]
n = len(data) # data is the given text to encode, or to use for compressCount
self.dp = [0] * (n+1)
self.opt = [0] * n
for i in reversed(range(n)):
  self.opt[i] = data[i] 
  self.dp[i] = self.dp[i+1] + 2 
  # start is the index of first symbol beginning with the byte at i
  start = self.sIndex[data[i]] 
  end = self.sIndex[data[i] + 1]
  for code in range(start, end):
    sym = self.symbols[code]
    L = len(sym)
    if (
      i + L <= len(data) 
      and self.dp[i] > 1 + self.dp[i + L] 
      and data[i:i + L] == sym
    ):
      self.dp[i] = 1 + self.dp[i + L]
      self.opt[i] = code
\end{lstlisting}

As the code shows, the DP table is filled from $n$ to 0 in descending order, where for each position other than $n$ the DP value is initialized with the corresponding value for the option of escaping the current byte. Then the inner loop iterates over the candidate symbols that begin with the current byte and match the next chunk of the text \texttt{data}.
This code uses the \texttt{st.sIndex} table, whose construction was shown in Lst.~\ref{algorithm3}. As a result, the iteration over the symbols is in decreasing order of their lengths. As a tie-breaker between symbols that yield the same DP value, this implementation chooses a symbol with the highest length (i.e., it occurs first in the iteration), thus the use of ``<'' instead of ``$\le$'' in the \texttt{if} statement for updating the DP and \texttt{opt} tables (line 14). There is an exception to this case, when choosing to escape the byte also yields the smallest DP value, then no symbol will be chosen.

This approach requires performing a memory comparison of at most 8 bytes for every symbol that begins with a certain byte. To avoid that, a trie is used in the C++ implementation of the contributions \cite{btrfsst_repo} to store the symbols in addition to the \texttt{hashTab} and \texttt{shortCodes} arrays. The trie is implemented as a vector of \texttt{TriNodes}, whose structure is shown in Lst.~\ref{TrieNode}.

\begin{lstlisting}[language=C++, caption={Trie node used to store FSST symbols for DP-based lookup.}, label={TrieNode}]
struct TrieNode {
  int symbolCode;      // code of a symbol ending here, -1 if none
  int child[256];      // child indices, -1 if absent
  TrieNode() : symbolCode(-1) {
    for (int i = 0; i < 256; i++) child[i] = -1;
  }
};
\end{lstlisting}

Each node stores the code of the symbol ending at that node and the indices for the children nodes, where the maximum number of children is 256 (an edge for every possible byte). The maximum number of nodes in the trie is $(8 * 255 + 1)$, as all symbols in the worst case don't share prefixes and there are at most 255 actual symbols, with an additional node for the root. This makes the additional trie memory overhead around $2 MB$ in the extreme case.

Now finding candidate symbols can be done efficiently by traversing the trie and comparing one byte at each iteration instead of a whole symbol, with the possibility to break from the inner loop when there are no symbols beginning with a certain prefix. The inner loop of the current implementation is shown in Lst.~\ref{dp_cpp}.

\begin{lstlisting}[language=C++, caption={Trie traversal in \texttt{st.buildDP}.}, label={dp_cpp}]
// walk trie for real symbols (1..8 bytes)
int node = 0;
int limit = min(Symbol::maxLength, n - (size_t)i);
for (int off = 0; off < limit; ++off) {
  u8 bb = data[i + off];
  node = trie[node].child[bb];
  if (node == -1) break;
  int code = trie[node].symbolCode;
  if (code != -1) {
    u32 L = off + 1;
    u32 cost = 1 + dpCost[i + L]; // real symbol always emits 1 byte
    if (cost <= bestCost) {
      bestCost = cost;
      bestCode = code;
    }
  }
}
\end{lstlisting}

This trie traversal from the root implies iterating over the symbols in increasing order of their lengths. Thus the use of $\le$ in the \texttt{if} statement for updating the DP value (line 12), in order to keep the same tie-break logic as in the python implementation. However in this case choosing a symbol will be preferred over escaping the byte, when both options result in the same DP value, which can be helpful in later generations to discover more symbol combinations.

A similar traversal is used for adding each symbol into the trie, where instead of breaking when \texttt{node == -1}, a new node is created and the child entry is updated accordingly. Here, breaking is faster in practice than continuing the 8 full iterations without branching, as in most cases no symbols will be found after the second or third iteration, due to the high number of symbols of lengths two and three in the symbol table. 

Having the trie as the structure used for the \texttt{findLongestSymbol} function, there is no need for the \texttt{sIndex} table and therefore the \texttt{makeIndex} function. As a result, including this method in the original C++ implementation of FSST, that already does not use \texttt{makeIndex}, becomes easier.     

After building the DP and \texttt{opt} tables, choosing the next symbol in \texttt{compressCount} or in the compression function can be done by a simple lookup in the \texttt{opt} table. The implementation wraps this operation in a function called \texttt{findBestSymbol}.

\section{$3^{rd}$ Counter}

The DP strategy introduced in the previous section replaces the greedy approach of the \texttt{findLongestSymbol} function. As a result, shorter symbols may become more valuable and therefore more frequent in terms of their counts computed by the \texttt{compressCount} function. To encourage the symbol selection method to still choose longer symbols, a third frequency counter \texttt{count3} is introduced. This counter keeps count of the appearances of all triples of consecutive symbols used for compressing the sample, in addition to the triples constructed from a pair of symbols followed by the next literal byte in the text data.

Counting triples of symbols will make converging the symbol table faster, and with combination of the DP approach of counting frequencies, more variation is introduced to candidate symbols from one generation to another. That means, adding a third counter while still having \texttt{findLongestSymbol} instead of the DP function will simulate skipping generations and quickly converging the symbol table to have long symbols that are concatenated from symbols of the first couple generations. The DP approach, on the other hand, balances the symbol selection by looking at the overall compression result and considering symbols that globally achieve the best compression, regardless of their lengths. Therefore, this combination improves the overall symbol selection. 

\paragraph{Integration into FSST} 
\mbox{}\\

This contribution affects both the \texttt{compressCount} and the \texttt{makeTable} functions. \texttt{compressCount} should now have a third variable (for example \texttt{prev2}), in addition to \texttt{code} and \texttt{prev} that were used in the implementation in Lst.~\ref{algorithm3}, to store the code chosen two steps ago. Then the triples, whose frequencies should be increased are (\texttt{prev2}, \texttt{prev}, \texttt{code}) and (\texttt{prev2}, \texttt{prev}, \texttt{nextByte}), in case \texttt{code} is an actual symbol and not a literal byte. 

The function \texttt{makeTable} should also consider all possible three-symbol concatenations as potential candidates and push them to the heap, with the gain being calculated as usual. 

Storing \texttt{count3} as a 3-dimensional table, analogous to \texttt{count1} and \texttt{count2}, would be highly inefficient: it would require $512^{3}$ entries and iterating over all three-symbol concatenations will be extremely slow. Noticing that we only need to consider triples having non-zero counts (i.e., they actually appear in the sample compression) makes it possible to store the triples in a hash map. The size of \texttt{count3} will be then linear to the sample size, same as \texttt{count1} and \texttt{count2}.



\begin{lstlisting}[language=C++, caption={Count3 structure.}, label={count3}]
struct Count3 {
  unordered_map<u32, u16> m;
  void clear() { m.clear(); }
  void inc(u16 a, u16 b, u16 c) {
    u32 k = pack3(a,b,c);
    auto it = m.find(k);
    if (it == m.end()) m.emplace(k, 1);
    else it->second++;
  }
  u16 get(u16 a, u16 b, u16 c) const {
    auto it = m.find(pack3(a,b,c));
    return it == m.end() ? 0 : it->second;
  }
};

static inline u32 pack3(u16 a, u16 b, u16 c) {
  // each code fits in 9 bits (0..511)
  return ((u32)a << 18) | ((u32)b << 9) | (u32)c;
}
\end{lstlisting}

The code snippet in Lst.~\ref{count3} shows the \texttt{count3} implementation in the C++ codebase of Ref.~\cite{btrfsst_repo}. As the codes take at most 9 bits each, the triple can be packed into 27 bits and therefore wrapped in an unsigned integer variable of 32 bits. This allows fast frequency addition and frequency query of a specific triple.


\section{Symbol Pruning}

Recall the baseline symbol selection in Lst.~\ref{algorithm3}. The \texttt{makeTable} function greedily takes the first 255 symbols in terms of static gain, without taking into account the conflicts between those symbols, and leaving most of the candidates in the heap unchosen. Especially that now the number of candidates grew by around $\times 1.5$ due to the third frequency counter, there is more potential to miss better symbols. Some of the chosen symbols may be a substring of other bigger symbols and therefore conflicting with them. It means that in \texttt{compressCount} of the next generation, the bigger symbol is most likely to be chosen over the smaller one. This possibility is higher when the smaller one is a prefix and it is certain when using \texttt{findLongestSymbol} instead of the DP function.
Then the new count of the smaller symbol will be smaller after the next generation than its current count. Therefore, one role of a generation, in addition to discovering new symbol combinations through concatenations, is correcting this overestimation in the counts of smaller symbols.

Symbol pruning is one step forward to this goal. By partially correcting the counts of symbols that are parts of other bigger symbols, we save time in the next generation and add more variety to the symbols chosen in the symbol table.
\newline

\noindent
When choosing a symbol in \texttt{makeTable} that is formed by a concatenation of two or three symbols, we know that we overestimated the counts for the symbols that were used in the concatenation, especially if they are not yet chosen into the symbol table (i.e., they have less gain).

The idea of the count correction that was used is subtracting the count of the bigger symbol from the counts of all smaller symbols used in the concatenation and all successive pairs of them, in case the bigger symbol is a three-symbol concatenation. For example, consider the symbols $A$, $B$, $C$, and $D=ABC$ a concatenation of the three first symbols. When $D$ is inserted in the new symbol table to construct, we reduce the count of $D$ from the counts of the symbols $A$, $B$, $C$, $AB$, and $BC$.
This reduction happens on the fly when choosing the symbols through the pop operations of the max heap. Then the updated symbols are pushed back to the heap with the updated gains and the old gains become invalid.

This reduction may lead to some symbols having negative counts due to overlap, when the smaller symbol is part of different bigger symbols that are chosen in the symbol table. Those bigger symbols may overlap exactly at the small symbol causing a double substraction from its count. A small example to illustrate this case is having a portion of a string compressed to symbols $ABC$, then choosing symbols $AB$ and $BC$ would decrease two occurences from the count of $B$, which actually appears only once. This problem can be modeled as an inclusion-exclusion problem, then the correction to the count of $B$ from the example is to add the count of the intersection of $AB$ and $BC$, which is $ABC$. 

Including concatenations of symbols and raw bytes into the counts and counting concatenation of symbols that may exceed the maximum symbol length make the simple addition of the count of the intersection symbol not enough to avoid negative counts. Therefore, the code is adapted to deal with negative gains by simply discarding such symbols and not pushing them back to the heap. Empirically, we observed that discarding symbols whose gains become negative does not reduce the compression factor.
\newline

\noindent
During symbol selection, if the smaller symbol occures before the bigger symbol that has it as a substring (the smaller symbol has more gain), it will not be pruned. Pruning such symbols proved to be significantly slower. A separate intermediate set has to be maintained for symbols that can be pruned, therefore not pushing them directly to the heap until the whole symbol selection process finishes. When pruned, they have to be removed from the intermediate set and pushed back to the heap.

As there was no noticeable benefit from this pruning direction in terms of compression factor, the symbol selection method pushes popped symbols from the max heap, that have not been pruned, directly to the new symbol table. Pruning will consequently only affect symbols with less gain that will occur afterwards in the extraction order.

\begin{lstlisting}[language=Python, caption={Implementation of pushing candidates into the heap.}, label={push_cand}]
def push_cand(code1: int, code2: int, code3: int, gain: int):
  if gain <= 0:
    return
  heapq.heappush(heap, (-gain, code1, code2, code3))
\end{lstlisting}

As the python implementation in Lst.~\ref{push_cand} shows, the symbol to push is always considered as the concatenation of three symbols and their codes are pushed to the heap along with the gain. Here, the gain is negated because the python \texttt{heapq} module implements a min heap. \texttt{code2} and \texttt{code3} are set to $-1$ denoting their absence, if the symbol to push is not a concatenation or is a concatenation of two symbols. The pruned symbols with negative gains are discarded as discussed earlier.
\noindent
\begin{minipage}{\textwidth}
  \captionsetup{type=lstlisting}
  \captionof{lstlisting}{Symbol pruning implementation.}
  \label{pruning}

  \vspace{4pt}
\noindent
\begin{minipage}[t]{0.49\textwidth}
\begin{lstlisting}[aboveskip=0pt, belowskip=0pt, basicstyle=\ttfamily\scriptsize, language=Python]
# Fill a new symbol table
res = SymbolTable()
seen: set[bytes] = set()  # avoid inserting duplicates
while res.nSymbols < MAX_REAL_SYMBOLS and heap:
  # g is negative gain
  g, code1, code2, code3 = heapq.heappop(heap)
  s = # reconstruct symbol
  curcnt = # restore current count
  if g != -curcnt * len(s) : 
    continue # gain is invalid
  if s in seen:
    continue
  seen.add(s)
  res.insert(s)
  if code2 == -1:
    continue # nothing to prune
  # Pruning
  # prev is the previous symbol table
  L1 = len(prev.symbols[code1])
  L2 = len(prev.symbols[code2])
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[t]{0.49\textwidth}
\captionsetup{type=lstlisting}
\begin{lstlisting}[firstnumber=last, aboveskip=0pt, belowskip=0pt, basicstyle=\ttfamily\scriptsize, language=Python]
  if code3 == -1: # two-code symbol
    # Update the counts of prefix and suffix symbols
    count1[code1] -= curcnt
    if code1 != code2:
      push_cand(code1, -1, -1, L1 * count1[code1])
    count1[code2] -= curcnt
    push_cand(code2, -1, -1, L2 * count1[code2])
  else: # three-code symbol
    L3 = len(prev.symbols[code3])
    # Update the counts of one code symbols 
    count1[code1] -= curcnt
    if code1 != code2 and code1 != code3:
      push_cand(code1, -1, -1, L1 * count1[code1])
    count1[code2] -= curcnt
    if code2 != code3:
      push_cand(code2, -1, -1, L2 * count1[code2])
    count1[code3] -= curcnt
    push_cand(code3, -1, -1, L3 * count1[code3])
    # pruning of two-code symbols
    L23 = min(MAX_SYMBOL_LEN, L2 + L3)
    count2[code1][code2] -= curcnt
    if code1 != code2 or code2 != code3:
      push_cand(code1, code2, -1, (L1 + L2) * count2[code1][code2])
    count2[code2][code3] -= curcnt
    push_cand(code2, code3, -1, L23 * count2[code2][code3])
    
\end{lstlisting}
\end{minipage}
\end{minipage}

The updated \texttt{makeTable} function now constructs the candidates from the \texttt{count1} and \texttt{count2} arrays as usual, but for three-symbol concatenations a loop over the HashMap of \texttt{count3} is added. Then the candidates are pushed with the \texttt{push\_cand} helper function before entering the while loop to choose the symbols of the next symbol table. This loop has now to first reconstruct the popped symbol and its current count from the codes, as shown in Lst.~\ref{pruning}. Then if the symbol has been already pruned, it will be discarded. This check is performed through the comparison of the symbol's current gain with its gain at insertion time into the heap. 
Next comes the insertion of the symbol to the new symbol table followed by the pruning logic. The \texttt{if} statements that precede some of the \texttt{push\_cand} operations (lines 24, 32, 35, and 42 in Lst.~\ref{pruning}) avoid pushing the same pruned symbol twice into the heap, as only the last push will be valid. This saves the insertion time and also the time of extracting those invalid states of the symbols. Therefore, if some symbol appears as part of the bigger symbol in multiple ways, it will be pushed only once to the heap after all reductions of its count.
\newline

\noindent
Symbol pruning complements the two previously introduced contributions by partially reducing the conflicts between symbols and their concatenations obtained from \texttt{compressCount}, especially after adding a third counter. Furthermore, pruning helped introduce more symbols, that would have been ignored, giving more options for the DP function to find a better compression with the new set of symbols in the following generation. 


\begin{comment}
Citation test~\parencite{latex}.

Acronyms must be added in \texttt{main.tex} and are referenced using macros. The first occurrence is automatically replaced with the long version of the acronym, while all subsequent usages use the abbreviation.

E.g. \texttt{\textbackslash ac\{TUM\}, \textbackslash ac\{TUM\}} $\Rightarrow$ \ac{TUM}, \ac{TUM}

For more details, see the documentation of the \texttt{acronym} package\footnote{\url{https://ctan.org/pkg/acronym}}.
\subsection{Subsection}

See~\autoref{tab:sample}, \autoref{fig:sample-drawing}, \autoref{fig:sample-plot}, \autoref{fig:sample-listing}.

\begin{table}[htpb]
  \caption[Example table]{An example for a simple table.}\label{tab:sample}
  \centering
  \begin{tabular}{l l l l}
    \toprule
      A & B & C & D \\
    \midrule
      1 & 2 & 1 & 2 \\
      2 & 3 & 2 & 3 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[htpb]
  \centering
  % This should probably go into a file in figures/
  \begin{tikzpicture}[node distance=3cm]
    \node (R0) {$R_1$};
    \node (R1) [right of=R0] {$R_2$};
    \node (R2) [below of=R1] {$R_4$};
    \node (R3) [below of=R0] {$R_3$};
    \node (R4) [right of=R1] {$R_5$};

    \path[every node]
      (R0) edge (R1)
      (R0) edge (R3)
      (R3) edge (R2)
      (R2) edge (R1)
      (R1) edge (R4);
  \end{tikzpicture}
  \caption[Example drawing]{An example for a simple drawing.}\label{fig:sample-drawing}
\end{figure}

\begin{figure}[htpb]
  \centering

  \pgfplotstableset{col sep=&, row sep=\\}
  % This should probably go into a file in data/
  \pgfplotstableread{
    a & b    \\
    1 & 1000 \\
    2 & 1500 \\
    3 & 1600 \\
  }\exampleA
  \pgfplotstableread{
    a & b    \\
    1 & 1200 \\
    2 & 800 \\
    3 & 1400 \\
  }\exampleB
  % This should probably go into a file in figures/
  \begin{tikzpicture}
    \begin{axis}[
        ymin=0,
        legend style={legend pos=south east},
        grid,
        thick,
        ylabel=Y,
        xlabel=X
      ]
      \addplot table[x=a, y=b]{\exampleA};
      \addlegendentry{Example A}
      \addplot table[x=a, y=b]{\exampleB};
      \addlegendentry{Example B}
    \end{axis}
  \end{tikzpicture}
  \caption[Example plot]{An example for a simple plot.}\label{fig:sample-plot}
\end{figure}

\begin{figure}[htpb]
  \centering
  \begin{tabular}{c}
  \begin{lstlisting}[language=SQL]
    SELECT * FROM tbl WHERE tbl.str = "str"
  \end{lstlisting}
  \end{tabular}
  \caption[Example listing]{An example for a source code listing.}\label{fig:sample-listing}
\end{figure}
\end{comment}